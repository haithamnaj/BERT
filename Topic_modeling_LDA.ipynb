{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Topic modeling LDA.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7wqBtUEUCwe",
        "outputId": "a07ce7ec-eb02-4680-ad0e-4575e6386218"
      },
      "source": [
        "pip install pyLDAvis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/38/6d81eff34c84c9158d3b7c846bff978ac88b0c2665548941946d3d591158/pyLDAvis-3.2.2.tar.gz (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.36.2)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/66/89/479de0afbbfb98d1c4b887936808764627300208bb771fcd823403645a36/funcy-1.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->pyLDAvis) (1.15.0)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.2.2-py2.py3-none-any.whl size=135593 sha256=b45e42e5d805afff85801124e7ae2adfad11e283cd6da2aed50d24b467861a0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/df/b6/97234c8446a43be05c9a8687ee0db1f1b5ade5f27729187eae\n",
            "Successfully built pyLDAvis\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-1.15 pyLDAvis-3.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9MOy9DuT0Ow"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "# import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSY2Aa6AT0Ox"
      },
      "source": [
        "df = pd.read_excel(\"/content/Midterm - WineBeerSpirits_ Reviews (2).xlsx\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1V-nwWiT0Oy"
      },
      "source": [
        "df[\"review\"] = df['reviews.text'].str.lower()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH3lNi7prCDD",
        "outputId": "2cf316e5-ed78-42e0-8cb0-c08f61b62814"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1oRwFvqq13U",
        "outputId": "9649f125-aa85-4deb-8ceb-388db6bf0e65"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpvIU1IzxkUf"
      },
      "source": [
        "STOPWORDS = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "    \"\"\"custom function to remove the stopwords\"\"\"\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "\n",
        "df[\"review\"] = df[\"review\"].apply(lambda text: remove_stopwords(text))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3auXXLMlxkW2"
      },
      "source": [
        "import string\n",
        "import re\n",
        "PUNCT_TO_REMOVE = string.punctuation\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
        "\n",
        "df[\"review\"] = df[\"review\"].apply(lambda text: remove_punctuation(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSQxuminxkZc"
      },
      "source": [
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "df[\"review\"] = df[\"review\"].apply(lambda text: remove_emoji(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thiDRZY3xkcM"
      },
      "source": [
        "def remove_urls(text):\n",
        "  \n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    try:\n",
        "        return url_pattern.sub(r'', text)\n",
        "    except:\n",
        "        print(text)\n",
        "    \n",
        "df[\"review\"] = df[\"review\"].apply(lambda text: remove_urls(text))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H4XVwkaT0Oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48718ec0-e8c6-450e-a18d-e107b842f175"
      },
      "source": [
        "import re, nltk, spacy, string\n",
        "import pandas as pd \n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from pprint import pprint\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from plotly.offline import plot\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n",
            "/usr/local/lib/python3.7/dist-packages/past/builtins/misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Mapping\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/plotly/express/_doc.py:503: DeprecationWarning:\n",
            "\n",
            "inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiMZw-bpT0Oz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lETARvBeT0O0"
      },
      "source": [
        "#df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-Wg1u_jT0O0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd54a90-21bb-4487-ecfe-cd670faf1e4f"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning:\n",
            "\n",
            "`scipy.sparse.sparsetools` is deprecated!\n",
            "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-0eZVHMT0O1"
      },
      "source": [
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6-XHeWwULsx",
        "outputId": "a8fa706a-36e4-4839-f68f-0d0d1a75fdc1"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS4ouDI2T0O1"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfoiu9QgT0O2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0AkCFmhT0O2"
      },
      "source": [
        "# # Convert to list\n",
        "# data = df['review'].values.tolist()\n",
        "\n",
        "# # Remove new line characters\n",
        "# sample_list =df[\"review\"].astype('str') \n",
        "# data = []\n",
        "\n",
        "# for element in sample_list:\n",
        "#     data.append(element.strip())\n",
        "\n",
        "# # Remove distracting single quotes\n",
        "\n",
        "# data = (df[\"reviewText\"].astype('str')).replace(\"'\",\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr-9-a0oT0O2",
        "outputId": "ed4377bd-d1cf-4e5d-d6e0-3d58fc6f514f"
      },
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(df['review']))\n",
        "\n",
        "print(data_words[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['fantastic', 'white', 'wine', 'occasion']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psMx8vHFT0O3",
        "outputId": "caba6fb4-84bb-4488-bbc2-3091b308bccf"
      },
      "source": [
        "# Build the bigram and trigram models\n",
        "\n",
        "bigram = gensim.models.Phrases(data_words, min_count=10, threshold=50) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=65)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "print(trigram_mod[bigram_mod[data_words[0]]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fantastic', 'white', 'wine', 'occasion']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFbdAADkT0O3"
      },
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "Ut6RYPw_T0O3",
        "outputId": "109ab432-6189-4d83-8872-e80766967e73"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\", \".join(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBXtxunrT0O4"
      },
      "source": [
        "# Remove Stop Words\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "    \"\"\"custom function to remove the stopwords\"\"\"\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "\n",
        "# data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_trigrams(data_words)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nP9w5ZoxKw3",
        "outputId": "947ea575-cfdf-4085-acfd-bfe7b967cdf5"
      },
      "source": [
        "print(data_lemmatized[:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['fantastic', 'white', 'wine', 'occasion'], ['tart', 'refresh']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIsK6gMoT0O4",
        "outputId": "9deb5f40-e81f-4a08-e598-11dec24d1280"
      },
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1)], [(4, 1), (5, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnysWX-Y6bvw",
        "outputId": "668dbc55-a72e-46c3-978c-518ccedadc1c"
      },
      "source": [
        "print(type(corpus))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0mmUXlreT0O5",
        "outputId": "cc232de0-c5c2-4c17-85e7-28b1a5af81c1"
      },
      "source": [
        "id2word[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'fantastic'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je-t9OSeT0O5",
        "outputId": "358669d0-b665-4437-fab2-401c539ee590"
      },
      "source": [
        "# Human readable format of corpus (term-frequency)\n",
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('fantastic', 1), ('occasion', 1), ('white', 1), ('wine', 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IZnTXWaT0O5",
        "outputId": "0d64ae9c-625d-4928-c33b-1bf45dcedb9f"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Build LDA model\n",
        "import numpy as np\n",
        "from numpy.random import randint\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=3, \n",
        "                                           random_state=42,\n",
        "                                           update_every=5,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.78 s, sys: 1.88 ms, total: 1.78 s\n",
            "Wall time: 1.78 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uxq34-jT0O6",
        "outputId": "8bce47e3-7e75-4904-8b2b-e0a131b1da85"
      },
      "source": [
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.035*\"wine\" + 0.019*\"great\" + 0.016*\"taste\" + 0.013*\"bottle\" + '\n",
            "  '0.011*\"purchase\" + 0.011*\"would\" + 0.010*\"sweet\" + 0.010*\"love\" + '\n",
            "  '0.010*\"order\" + 0.009*\"try\"'),\n",
            " (1,\n",
            "  '0.045*\"wine\" + 0.025*\"good\" + 0.019*\"love\" + 0.016*\"taste\" + 0.014*\"use\" + '\n",
            "  '0.014*\"buy\" + 0.014*\"great\" + 0.012*\"bottle\" + 0.012*\"order\" + '\n",
            "  '0.010*\"make\"'),\n",
            " (2,\n",
            "  '0.030*\"wine\" + 0.017*\"taste\" + 0.017*\"good\" + 0.011*\"red\" + 0.010*\"case\" + '\n",
            "  '0.008*\"qvc\" + 0.007*\"say\" + 0.007*\"bottle\" + 0.006*\"quality\" + '\n",
            "  '0.006*\"½i_½i\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGMrxjWMT0O6",
        "outputId": "4864d955-ba7c-4c69-a7df-23059d1278b6"
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -6.8451736861307335\n",
            "\n",
            "Coherence Score:  0.48664511236792124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "1xJSeK0gT0O7",
        "outputId": "77b701d5-9921-4a31-9d69-41a48490f4af"
      },
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
        "vis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el721406999605740323743764633\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el721406999605740323743764633_data = {\"mdsDat\": {\"x\": [0.13382367728787423, 0.07354552230925185, -0.04897540340280455, -0.1583937961943216], \"y\": [-0.018728649128817852, 0.09141731540496596, -0.1437640501105579, 0.07107538383440981], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [63.233509976796284, 13.87204366530908, 12.153375997101872, 10.741070360792762]}, \"tinfo\": {\"Term\": [\"love\", \"purchase\", \"try\", \"tea\", \"buy\", \"first\", \"friend\", \"taste\", \"new\", \"dry\", \"wine\", \"case\", \"say\", \"smooth\", \"flavor\", \"thank\", \"go\", \"qvc\", \"far\", \"would\", \"good\", \"send\", \"\\u00bdi_\\u00bdi\", \"money\", \"drain\", \"chardonnay\", \"usually\", \"enjoy\", \"next\", \"favorite\", \"again\", \"perfect\", \"think\", \"delicious\", \"set\", \"wait\", \"pinot\", \"much\", \"excellent\", \"long\", \"better\", \"glass\", \"can\", \"value\", \"cocktail\", \"dark\", \"sweet\", \"sure\", \"hope\", \"absolutely\", \"arrive\", \"local\", \"flavorful\", \"surprise\", \"refreshing\", \"soda\", \"sip\", \"quite\", \"definitely\", \"never\", \"blend\", \"order\", \"red\", \"wine\", \"good\", \"love\", \"bottle\", \"taste\", \"drink\", \"really\", \"buy\", \"gift\", \"well\", \"great\", \"use\", \"would\", \"price\", \"nice\", \"time\", \"make\", \"also\", \"even\", \"enjoy\", \"have\", \"find\", \"be\", \"smooth\", \"purchase\", \"try\", \"get\", \"delivery\", \"second\", \"describe\", \"suppose\", \"cloudy\", \"shipment\", \"poor\", \"salad\", \"dressing\", \"opinion\", \"decision\", \"disappointing\", \"flag\", \"mispronounce\", \"private\", \"regret\", \"repeatedly\", \"reserve\", \"sound\", \"sub\", \"tout\", \"juicer\", \"foot\", \"apologize\", \"coin\", \"embarrassed\", \"expression\", \"giftthis\", \"offensive\", \"period\", \"must\", \"horrible\", \"already\", \"collection\", \"oaky\", \"qvc\", \"miss\", \"far\", \"consider\", \"purchase\", \"\\u00bdi_\\u00bdi\", \"case\", \"decide\", \"say\", \"quality\", \"go\", \"deliver\", \"receive\", \"cancel\", \"pair\", \"wine\", \"first\", \"next\", \"taste\", \"would\", \"white\", \"enjoy\", \"give\", \"chardonnay\", \"good\", \"use\", \"year\", \"bottle\", \"be\", \"try\", \"great\", \"order\", \"complaint\", \"several\", \"assortment\", \"cent\", \"promotion\", \"truly\", \"hook\", \"chinese\", \"tonight\", \"generally\", \"fabulous\", \"country\", \"drank\", \"scotch\", \"pleasure\", \"weekend\", \"everyone\", \"past\", \"charge\", \"game\", \"write\", \"ginseng\", \"bag\", \"green_tea\", \"tea\", \"tasti\", \"excite\", \"collect\", \"german\", \"varietal\", \"palate\", \"beer\", \"restaurant\", \"neat\", \"first\", \"thank\", \"try\", \"awesome\", \"usually\", \"friend\", \"hand\", \"ago\", \"love\", \"flavor\", \"smooth\", \"family\", \"son\", \"especially\", \"visit\", \"day\", \"favorite\", \"taste\", \"get\", \"price\", \"way\", \"year\", \"always\", \"great\", \"find\", \"drink\", \"wine\", \"be\", \"store\", \"money\", \"send\", \"cooler\", \"refund\", \"immediately\", \"unfortunately\", \"rest\", \"acceptablei\", \"control\", \"garbage\", \"gifted\", \"horrify\", \"luckily\", \"reputable\", \"spend\", \"text\", \"upset\", \"impact\", \"social\", \"spread\", \"word\", \"smile\", \"rotten\", \"same\", \"sorry\", \"spoil\", \"highly\", \"hassle\", \"option\", \"personally\", \"tannic\", \"drain\", \"dump\", \"pour\", \"plastic\", \"cabernet\", \"\\u00bdi_\\u00bdi\", \"son\", \"new\", \"least\", \"almost\", \"apple\", \"cork\", \"whole\", \"week\", \"black\", \"dry\", \"support\", \"buy\", \"work\", \"great\", \"disappoint\", \"qvc\", \"next\", \"quality\", \"chardonnay\", \"still\", \"make\", \"cause\", \"wine\", \"good\", \"say\", \"bottle\", \"rise\"], \"Freq\": [123.0, 69.0, 71.0, 20.0, 89.0, 25.0, 36.0, 159.0, 22.0, 35.0, 368.0, 29.0, 50.0, 45.0, 43.0, 23.0, 51.0, 18.0, 18.0, 75.0, 148.0, 10.0, 15.0, 9.0, 11.0, 27.0, 16.0, 52.0, 19.0, 41.0, 32.46889978759311, 21.030269010364414, 23.56582437283494, 16.769016282958614, 15.056448738321933, 14.5894334148675, 16.66347770562234, 33.311480834202925, 14.43652966136847, 13.630748079972406, 13.216396456198547, 21.888843723103225, 27.236443639902216, 18.898221623254702, 11.089693915517328, 12.33935525136395, 72.3920278630826, 10.601385721196806, 19.703734804256577, 10.586298076703022, 11.449306845700189, 10.147924617649036, 9.379349870592932, 10.183978828976377, 8.851342260606698, 8.483107819284532, 11.700306174741243, 11.739473558153493, 13.327339827259477, 17.679264202552737, 14.553117615338714, 86.51742560760276, 60.28713193677248, 326.47421745620363, 130.86603747809508, 107.26341364004638, 95.35534103630714, 134.76311310617822, 56.79351251138529, 39.57911234181781, 75.79806428877335, 38.65162139994508, 42.12296767993003, 104.72245484628975, 51.32964890099076, 62.188180592743315, 53.91084322998222, 33.18899215887612, 38.953641327776374, 58.802880481771304, 30.157833424873406, 35.020335733793054, 41.99082476504363, 38.76269284022963, 36.90408686994331, 40.61522233458654, 34.78375645435668, 44.919479072359124, 38.2510944401299, 32.90018788497201, 9.468943061051947, 8.223060301695782, 6.9252210518715245, 6.60691431992435, 4.0213290063786085, 5.064604108703189, 3.0461151371437403, 3.0435363219672555, 3.0435159975082846, 3.0256684325299084, 2.727031592419134, 2.727031592419134, 2.727031592419134, 2.727031592419134, 2.727031592419134, 2.727031592419134, 2.727031592419134, 2.727031592419134, 2.727031592419134, 2.727031592419134, 2.727031592419134, 2.7268791589768524, 2.7254456868411983, 2.725393082359156, 2.725393082359156, 2.725393082359156, 2.725393082359156, 2.725393082359156, 2.725393082359156, 2.725393082359156, 5.457906898696589, 4.284685275717815, 3.229957340763131, 6.5410009039252985, 5.309764906148694, 10.063001890086863, 3.160758834638355, 9.81601607578141, 4.4885384036395735, 23.17690831629614, 7.890790666435596, 12.04076781920708, 5.271097025178344, 13.735897039652263, 7.915734755374945, 12.97304118775117, 3.9824668474916245, 6.596375490169732, 3.912661596488747, 3.041766300702172, 29.81617977268037, 7.805162525234767, 6.781390235738281, 15.667155824421412, 11.306388925437043, 6.550119412664774, 8.988912217960468, 8.208477502384158, 6.71682062514413, 11.788404989947413, 7.816576502281545, 6.361848569213444, 7.549517893629505, 6.686984917153047, 6.81508818871204, 6.942352179671176, 6.756016942047723, 4.823273162546996, 4.3752611372769605, 4.335901457772378, 4.7284788379307985, 3.919594989952232, 3.91577866512072, 4.253846284159903, 3.809086016935546, 3.418182174035133, 3.397148395244737, 2.9646315810066706, 2.964451160544964, 2.9125775282907487, 4.26056033443299, 2.5126107649554075, 2.5113441557053715, 2.510242517269378, 2.5071717034022756, 2.5062038746265607, 2.503957129254365, 2.50375104666603, 2.454144061025069, 2.451523643666146, 2.799771794940785, 16.622096810830197, 2.062151279822759, 2.0618651994825345, 2.0599620123770435, 2.0599620123770435, 2.0571124688875058, 3.3144404085538373, 6.695410665968157, 3.333517057401134, 3.7272782995441345, 11.573027309528173, 10.793099767290558, 23.181889422167558, 5.62382310397364, 7.1651983149749086, 11.44183832846676, 5.239199150061104, 5.0981532937898795, 15.747584954441246, 9.407515661034678, 9.156429034628527, 5.068343329550867, 4.518549025468551, 4.041615521629417, 3.8029024918517442, 5.204752196655328, 6.488221987603362, 9.239116596361496, 6.560973069162285, 6.899198326979331, 4.9312693420215385, 5.806371951039822, 4.777762166546114, 6.482205004484212, 5.500536486763289, 5.411307701324322, 5.534053319007989, 4.628882029616925, 4.533668207787877, 9.284867165419326, 9.608161935471554, 5.5724024611478695, 5.543184126295538, 5.501694053776637, 4.522602584654037, 3.8269925139170686, 2.867459777593752, 2.867459777593752, 2.867459777593752, 2.867459777593752, 2.867459777593752, 2.867459777593752, 2.867459777593752, 2.867459777593752, 2.867459777593752, 2.867459777593752, 2.862618057989741, 2.862618057989741, 2.862618057989741, 2.862618057989741, 2.86074903989682, 2.859181573385756, 2.859181573385756, 2.859181573385756, 2.859181573385756, 2.8215957028514485, 2.84984458292527, 3.1119026275637895, 2.4985629100752473, 2.815305933939933, 8.977563192067008, 5.587179645802299, 7.190381986460087, 3.4932667899911265, 3.493560704426244, 6.916709693060643, 5.441989617713255, 7.943839740888038, 5.128871229976768, 5.060728441052554, 4.102397513911572, 3.9572977430112655, 4.362784874843703, 5.383726056668016, 5.356189745527838, 7.299188184625847, 3.742069756463223, 10.105333708195053, 6.42800219321115, 11.585440517709209, 4.6445025551899395, 5.453128743375522, 5.51188941324488, 5.351283457319577, 5.472190135921995, 4.953342289322921, 6.344795710915441, 4.498335898033026, 6.946166862320093, 5.909604706841005, 5.078261478536416, 5.27507584143869, 4.679018755592437], \"Total\": [123.0, 69.0, 71.0, 20.0, 89.0, 25.0, 36.0, 159.0, 22.0, 35.0, 368.0, 29.0, 50.0, 45.0, 43.0, 23.0, 51.0, 18.0, 18.0, 75.0, 148.0, 10.0, 15.0, 9.0, 11.0, 27.0, 16.0, 52.0, 19.0, 41.0, 32.989472271704166, 21.523409875277743, 24.231384246379132, 17.261228367875237, 15.556518145308175, 15.11785194740866, 17.28258013924362, 34.554989505137826, 15.008011849986588, 14.170451505065136, 13.744613478717161, 22.771067381706995, 28.340149406743873, 19.71580322050267, 11.57469775225649, 12.890918292114193, 75.72009960239534, 11.097688780916965, 20.626239864726518, 11.098606867361276, 12.029249104827022, 10.666583247483334, 9.868941865371083, 10.718340919985371, 9.344347600973462, 8.968236243553699, 12.369957342541596, 12.420372249817099, 14.107146323393723, 18.72262848947954, 15.429861843104714, 94.27843960543646, 65.7231212602853, 368.770617410212, 148.86625288846346, 123.48982811581222, 109.95071512315342, 159.89805749534304, 64.92862319383907, 44.51870089028057, 89.29548404953181, 43.68511054555239, 48.109093932985296, 129.73245254815436, 60.03760355979197, 75.01966829104217, 64.52576436185117, 37.943268718738096, 45.60598167669709, 73.79364711873134, 34.59760821707883, 41.32175535583572, 52.04854737877045, 47.25527543937678, 46.74337424039929, 53.515881701227556, 45.711763121668014, 69.53955524940142, 71.39484797344302, 46.59897333792152, 10.086544987051727, 8.770296552081987, 7.474315918069885, 7.1597209822631935, 4.5650600229346505, 5.951145176171844, 3.5812945242964225, 3.582144015610061, 3.5821516614372833, 3.5884997853934406, 3.2678249319269375, 3.2678249319269375, 3.2678249319269375, 3.2678249319269375, 3.2678249319269375, 3.2678249319269375, 3.2678249319269375, 3.2678249319269375, 3.2678249319269375, 3.2678249319269375, 3.2678249319269375, 3.267884638503333, 3.268390491201946, 3.268537815038226, 3.268537815038226, 3.268537815038226, 3.268537815038226, 3.268537815038226, 3.268537815038226, 3.268537815038226, 6.654600566008865, 5.348697235470886, 3.946405420657787, 9.0381909885609, 7.7244760561866315, 18.449375829661125, 3.9826658856472883, 18.533152415291003, 6.580387496339577, 69.53955524940142, 15.286860103342763, 29.86618916668462, 9.168608445906786, 50.1031437113792, 20.502371251103114, 51.424596050389226, 6.43199207297159, 16.369309339139335, 6.459253843182466, 4.0352517989240475, 368.770617410212, 25.64411505781443, 19.967266122666867, 159.89805749534304, 75.01966829104217, 22.015782516601057, 52.04854737877045, 41.50391631284228, 27.494217951262836, 148.86625288846346, 60.03760355979197, 33.93003922193162, 109.95071512315342, 53.515881701227556, 71.39484797344302, 129.73245254815436, 94.27843960543646, 5.302841533278254, 4.850684499094004, 4.848227015978341, 5.297196331149618, 4.398046551001755, 4.397566735888874, 4.778415031770505, 4.291476291485412, 3.893017110844684, 3.8887531538524667, 3.4405020983889503, 3.44049109501898, 3.387298392243452, 5.058347205706522, 2.9880729868029543, 2.988002319592536, 2.9879147781768403, 2.9875817692882105, 2.987361886680025, 2.9875719937370526, 2.98756148354698, 2.934572104645915, 2.9335410160672377, 3.3806967411332023, 20.104181473330076, 2.5357424052123365, 2.5357256193666013, 2.5356148691892924, 2.5356148691892924, 2.535342751961453, 4.2104040156997655, 10.01035892767466, 4.77769083262669, 5.574399956694334, 25.64411505781443, 23.796353095164722, 71.39484797344302, 10.144412662309122, 16.672402315924288, 36.4594074209468, 10.06173430301863, 11.989484015773158, 123.48982811581222, 43.63919758602665, 45.711763121668014, 12.956458347467443, 10.353585301299468, 8.167154838498169, 6.997676769546908, 19.620254271625864, 41.245197402826946, 159.89805749534304, 46.59897333792152, 64.52576436185117, 16.96596935738087, 33.93003922193162, 15.12661235070874, 129.73245254815436, 46.74337424039929, 64.92862319383907, 368.770617410212, 53.515881701227556, 27.180595472615643, 9.849963501474377, 10.5310486500331, 6.129567657857634, 6.125592784578626, 6.133861288248333, 5.1039645794075295, 4.403920145877456, 3.3992023991728386, 3.3992023991728386, 3.3992023991728386, 3.3992023991728386, 3.3992023991728386, 3.3992023991728386, 3.3992023991728386, 3.3992023991728386, 3.3992023991728386, 3.3992023991728386, 3.400433138857103, 3.400433138857103, 3.400433138857103, 3.400433138857103, 3.4012952445721973, 3.4011779357638354, 3.4011779357638354, 3.4011779357638354, 3.4011779357638354, 3.363161010542764, 3.4018951744530597, 3.75521766710943, 3.029550181099449, 3.414357123270739, 11.372136035895789, 7.421754318712657, 10.159426579606496, 4.37392490548573, 4.389942699189254, 15.286860103342763, 10.353585301299468, 22.892643404165646, 10.191780474338893, 10.63500269872436, 7.099283781279391, 6.677603447817663, 8.601602520488719, 14.144924982864858, 13.988727359083011, 35.550202610459245, 6.655967842779191, 89.29548404953181, 27.42361200702764, 129.73245254815436, 12.023119981196718, 18.449375829661125, 19.967266122666867, 20.502371251103114, 27.494217951262836, 19.256570744743975, 73.79364711873134, 13.882041231929453, 368.770617410212, 148.86625288846346, 50.1031437113792, 109.95071512315342, 24.76713681368958], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.1942, -5.6285, -5.5147, -5.8549, -5.9627, -5.9942, -5.8613, -5.1686, -6.0047, -6.0621, -6.093, -5.5885, -5.3699, -5.7354, -6.2685, -6.1617, -4.3924, -6.3135, -5.6937, -6.3149, -6.2365, -6.3572, -6.436, -6.3537, -6.4939, -6.5364, -6.2149, -6.2115, -6.0847, -5.8021, -5.9967, -4.2141, -4.5754, -2.8861, -3.8003, -3.9992, -4.1169, -3.771, -4.6351, -4.9962, -4.3464, -5.0199, -4.9339, -4.0232, -4.7362, -4.5443, -4.6871, -5.1723, -5.0121, -4.6003, -5.268, -5.1185, -4.937, -5.017, -5.0662, -4.9703, -5.1253, -4.8696, -5.0303, -5.181, -4.9095, -5.0506, -5.2223, -5.2694, -5.7659, -5.5352, -6.0436, -6.0445, -6.0445, -6.0504, -6.1543, -6.1543, -6.1543, -6.1543, -6.1543, -6.1543, -6.1543, -6.1543, -6.1543, -6.1543, -6.1543, -6.1544, -6.1549, -6.1549, -6.1549, -6.1549, -6.1549, -6.1549, -6.1549, -6.1549, -5.4605, -5.7025, -5.985, -5.2794, -5.488, -4.8487, -6.0067, -4.8735, -5.656, -4.0144, -5.0918, -4.6692, -5.4953, -4.5375, -5.0887, -4.5946, -5.7756, -5.271, -5.7933, -6.0451, -3.7625, -5.1027, -5.2433, -4.406, -4.7321, -5.278, -4.9615, -5.0523, -5.2529, -4.6904, -5.1013, -5.3072, -5.136, -5.2574, -5.2384, -5.2199, -5.2471, -5.4518, -5.5493, -5.5583, -5.4716, -5.6593, -5.6602, -5.5774, -5.6879, -5.7961, -5.8023, -5.9385, -5.9386, -5.9562, -5.5758, -6.1039, -6.1044, -6.1049, -6.1061, -6.1065, -6.1074, -6.1075, -6.1275, -6.1285, -5.9957, -4.2145, -6.3015, -6.3016, -6.3026, -6.3026, -6.3039, -5.827, -5.1238, -5.8212, -5.7096, -4.5766, -4.6463, -3.8819, -5.2982, -5.056, -4.588, -5.3691, -5.3964, -4.2686, -4.7837, -4.8108, -5.4022, -5.5171, -5.6286, -5.6895, -5.3757, -5.1553, -4.8018, -5.1441, -5.0938, -5.4297, -5.2663, -5.4613, -5.1562, -5.3204, -5.3368, -5.3143, -5.4929, -5.5137, -4.6733, -4.6391, -5.1839, -5.1891, -5.1967, -5.3926, -5.5596, -5.8483, -5.8483, -5.8483, -5.8483, -5.8483, -5.8483, -5.8483, -5.8483, -5.8483, -5.8483, -5.85, -5.85, -5.85, -5.85, -5.8506, -5.8512, -5.8512, -5.8512, -5.8512, -5.8644, -5.8545, -5.7665, -5.986, -5.8666, -4.707, -5.1812, -4.929, -5.6509, -5.6508, -4.9678, -5.2076, -4.8293, -5.2668, -5.2802, -5.4901, -5.5262, -5.4286, -5.2183, -5.2235, -4.914, -5.5821, -4.5887, -5.0411, -4.452, -5.366, -5.2055, -5.1948, -5.2244, -5.202, -5.3017, -5.0541, -5.398, -4.9635, -5.1251, -5.2767, -5.2387, -5.3586], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.4424, 0.4352, 0.4305, 0.4294, 0.4257, 0.4228, 0.4219, 0.4217, 0.4195, 0.4195, 0.4191, 0.4188, 0.4186, 0.416, 0.4155, 0.4146, 0.4134, 0.4126, 0.4126, 0.4111, 0.4089, 0.4085, 0.4075, 0.4072, 0.4041, 0.4027, 0.4027, 0.402, 0.4015, 0.401, 0.3998, 0.3724, 0.372, 0.3365, 0.3295, 0.3175, 0.3159, 0.2873, 0.3245, 0.3407, 0.2945, 0.3359, 0.3255, 0.2442, 0.3016, 0.2708, 0.2786, 0.3245, 0.3007, 0.2313, 0.321, 0.2929, 0.2436, 0.2602, 0.222, 0.1825, 0.1851, 0.0213, -0.1657, 0.1102, 1.9121, 1.9109, 1.899, 1.8949, 1.8485, 1.814, 1.8134, 1.8124, 1.8123, 1.8047, 1.7944, 1.7944, 1.7944, 1.7944, 1.7944, 1.7944, 1.7944, 1.7944, 1.7944, 1.7944, 1.7944, 1.7943, 1.7936, 1.7936, 1.7936, 1.7936, 1.7936, 1.7936, 1.7936, 1.7936, 1.7771, 1.7535, 1.775, 1.6519, 1.6004, 1.3691, 1.7442, 1.3397, 1.5927, 0.8766, 1.314, 1.0669, 1.4217, 0.6812, 1.0236, 0.5981, 1.4959, 1.0664, 1.474, 1.6927, -0.5398, 0.7858, 0.8954, -0.3477, 0.0829, 0.763, 0.2191, 0.3547, 0.5659, -0.5606, -0.0634, 0.3013, -0.7033, -0.1045, -0.3738, -0.9525, -0.6605, 2.0128, 2.0044, 1.9959, 1.994, 1.9924, 1.9915, 1.9913, 1.9883, 1.9775, 1.9724, 1.9587, 1.9586, 1.9566, 1.9359, 1.9343, 1.9338, 1.9334, 1.9323, 1.9319, 1.931, 1.9309, 1.9288, 1.9281, 1.919, 1.9174, 1.9008, 1.9007, 1.8998, 1.8998, 1.8985, 1.8683, 1.7054, 1.7476, 1.7051, 1.3119, 1.3169, 0.9827, 1.5177, 1.263, 0.9486, 1.455, 1.2524, 0.0481, 0.5731, 0.4997, 1.169, 1.2784, 1.4041, 1.4977, 0.7806, 0.258, -0.7435, 0.1471, -0.1281, 0.872, 0.3422, 0.9551, -0.8889, -0.0323, -0.3772, -2.0917, -0.3401, 0.3166, 2.172, 2.1394, 2.1358, 2.1312, 2.1223, 2.1102, 2.0907, 2.061, 2.061, 2.061, 2.061, 2.061, 2.061, 2.061, 2.061, 2.061, 2.061, 2.0589, 2.0589, 2.0589, 2.0589, 2.058, 2.0575, 2.0575, 2.0575, 2.0575, 2.0555, 2.054, 2.0432, 2.0384, 2.0382, 1.9947, 1.9472, 1.8854, 2.0063, 2.0027, 1.438, 1.5879, 1.1727, 1.5444, 1.4885, 1.6827, 1.7079, 1.5523, 1.2651, 1.2711, 0.6479, 1.6552, 0.0522, 0.7804, -0.1846, 1.2799, 1.0123, 0.9439, 0.8879, 0.6168, 0.8733, -0.2225, 1.1042, -1.7409, -0.9954, -0.058, -0.8059, 0.5647]}, \"token.table\": {\"Topic\": [1, 4, 1, 1, 3, 4, 1, 4, 2, 1, 2, 1, 3, 4, 2, 1, 2, 4, 1, 3, 1, 3, 4, 3, 1, 2, 3, 4, 1, 3, 1, 1, 3, 4, 1, 3, 1, 2, 3, 4, 1, 2, 4, 4, 1, 4, 2, 3, 1, 2, 3, 1, 4, 3, 1, 2, 4, 3, 3, 2, 1, 2, 3, 2, 3, 3, 1, 2, 4, 4, 2, 4, 3, 1, 1, 2, 3, 4, 1, 2, 4, 2, 1, 1, 2, 3, 2, 2, 1, 2, 4, 2, 3, 4, 3, 2, 1, 2, 3, 1, 4, 2, 4, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 3, 2, 3, 1, 3, 4, 1, 2, 1, 3, 4, 1, 2, 3, 1, 2, 3, 2, 1, 3, 4, 1, 2, 1, 2, 3, 4, 3, 4, 3, 3, 1, 2, 3, 4, 1, 4, 4, 2, 3, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 3, 1, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 4, 4, 2, 1, 2, 4, 1, 1, 1, 3, 4, 1, 2, 3, 4, 2, 2, 4, 1, 3, 2, 3, 2, 3, 4, 1, 2, 1, 4, 1, 2, 4, 1, 3, 4, 2, 3, 2, 2, 4, 1, 2, 3, 2, 3, 3, 3, 1, 2, 4, 1, 4, 3, 2, 3, 4, 1, 2, 3, 4, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 1, 2, 4, 1, 2, 4, 1, 2, 1, 2, 1, 4, 2, 2, 4, 2, 4, 2, 3, 1, 4, 4, 2, 4, 1, 2, 3, 4, 3, 2, 2, 4, 1, 3, 1, 2, 1, 4, 1, 3, 4, 4, 1, 3, 4, 4, 2, 4, 4, 4, 1, 4, 1, 3, 2, 1, 4, 2, 1, 1, 1, 2, 3, 4, 1, 2, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 2, 3, 1, 2, 3, 4, 4, 4, 1, 2, 4, 1, 3, 1, 3, 1, 3, 1, 1, 2, 3, 4, 1, 3, 4, 3, 1, 2, 4, 1, 2, 1, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 2, 4], \"Freq\": [0.9911153833503862, 0.882559979579333, 0.9700064231535811, 0.5004385503251436, 0.41703212527095296, 0.0834064250541906, 0.4701456258774374, 0.4701456258774374, 0.7601854549196214, 0.8671119636874419, 0.11561492849165893, 0.5949778966589512, 0.33054327592163957, 0.06610865518432792, 0.9178416067873807, 0.1408592797257903, 0.2817185594515806, 0.5634371189031612, 0.9144377927618099, 0.8250438741455728, 0.29572929452547775, 0.5914585890509555, 0.09857643150849257, 0.6817699118730028, 0.7661277119360165, 0.1308022922817589, 0.09343020877268493, 0.03737208350907397, 0.29968955375877615, 0.6992756254371444, 0.9458250695903412, 0.3574306562457559, 0.2144583937474535, 0.3574306562457559, 0.9721409143208363, 0.06480939428805575, 0.8640234844638578, 0.07275987237590381, 0.018189968093975953, 0.04547492023493988, 0.851106870733162, 0.03359632384473008, 0.11198774614910027, 0.6833802182780309, 0.9527119851236575, 0.035285629078653985, 0.6192665742997344, 0.3096332871498672, 0.5357228507026203, 0.40179213802696523, 0.06696535633782753, 0.6483196418765498, 0.28814206305624435, 0.943895541609061, 0.545569254837126, 0.2545989855906588, 0.181856418279042, 1.0042305263973292, 0.9320801813437205, 0.8762206805396172, 0.950348789699977, 0.9178416067873807, 0.7887633190285939, 0.7744912680933035, 0.22128321945522955, 0.9428907065433209, 0.30393346913271063, 0.6078669382654213, 0.882559979579333, 0.9788618602338881, 0.29950865091481715, 0.5990173018296343, 0.8719685408700207, 0.9308879110141286, 0.4077419124771142, 0.05096773905963928, 0.2548386952981964, 0.2548386952981964, 0.3272034156218454, 0.5453390260364089, 0.10906780520728179, 0.9180418359287659, 0.9215187609163907, 0.9848661774059251, 0.6218913137049303, 0.31094565685246517, 0.8922777830816653, 0.9365405579227418, 0.24951925995014448, 0.33269234660019265, 0.4158654332502408, 0.9180418359287659, 0.17586845546756238, 0.7914080496040308, 0.8856615664181451, 0.8374854789917789, 0.8778870888703613, 0.04620458362475585, 0.0770076393745931, 0.7876185772218948, 0.1969046443054737, 0.13473903299098364, 0.8084341979459019, 0.9178416067873807, 0.8069389467174822, 0.17291548858231762, 0.019212832064701958, 0.4897666420066975, 0.4897666420066975, 0.8470114519241274, 0.14520196318699327, 1.004044700977226, 0.9328350843494644, 0.7887288690562585, 0.9178416067873807, 0.8719657521513445, 0.3859079283790029, 0.3859079283790029, 0.15436317135160116, 0.43165889001158286, 0.5395736125144786, 0.7516026580557779, 0.1454714822043441, 0.0969809881362294, 0.7915560355080592, 0.08557362546033072, 0.12836043819049608, 0.23397180937899603, 0.311962412505328, 0.46794361875799206, 0.9180418359287659, 0.7103705318799505, 0.20623660602966304, 0.04583035689548068, 0.9119518711099014, 0.9178829788165105, 0.6034107945309192, 0.02742776338776905, 0.3017053972654596, 0.0548555267755381, 1.0041599018497296, 0.882559979579333, 0.7714554977674511, 0.7887633190285939, 0.708170108399043, 0.08583880101806582, 0.1502179017816152, 0.06437910076354937, 0.8927526910875727, 0.11445547321635548, 0.882559979579333, 0.9178416067873807, 0.6815303658184674, 0.746917465964721, 0.19275289444250865, 0.02409411180531358, 0.04818822361062716, 0.9661382855365652, 0.04391537661529842, 0.6222703231085039, 0.25279731876282974, 0.038891895194281496, 0.09722973798570374, 0.8799845328151735, 0.08060927018154261, 0.040304635090771306, 0.8093580128767387, 0.053957200858449246, 0.04624902930724221, 0.09249805861448442, 0.8873910408759131, 0.49693222355314487, 0.49693222355314487, 0.8818613878901561, 0.8253046805331317, 0.08464663390083402, 0.08464663390083402, 0.8920179529304917, 0.837097651293365, 0.9696386802037793, 0.7478456573449797, 0.1869614143362449, 0.882559979579333, 0.9781766685032813, 0.8822405492167124, 0.9180250626515316, 0.2943548487483096, 0.09811828291610321, 0.490591414580516, 0.9375073318214989, 0.9879713426912184, 0.86646812642457, 0.12956532731582354, 0.882559979579333, 0.7995268197690664, 0.08130781217990506, 0.04065390608995253, 0.08130781217990506, 0.9180418359287659, 0.7532642923453321, 0.9137089694446937, 0.9549995665631262, 0.02893938080494322, 0.7513598976232436, 0.15027197952464874, 0.17939150541200283, 0.7175660216480113, 0.17939150541200283, 0.961403470143864, 0.05341130389688133, 0.6552323266115495, 0.3494572408594931, 0.3505737819587425, 0.3505737819587425, 0.30049181310749357, 0.8697194815928737, 0.02635513580584466, 0.10542054322337864, 0.6472930932312796, 0.2589172372925118, 0.9178416067873807, 0.836003951347898, 0.798888444277384, 0.922798471889253, 0.07424815291062956, 0.010606878987232794, 0.7434480298850037, 0.2478160099616679, 0.7125206960694489, 1.0041566161768178, 0.9756818330222414, 0.9178416067873807, 0.6601640113035471, 0.9836494240462416, 0.6858828317416772, 1.0039915401162296, 0.8376859204534084, 0.19686150437020686, 0.689015265295724, 0.8368750147177768, 0.015497685457736608, 0.10848379820415625, 0.030995370915473216, 0.9180418359287659, 0.9094946935222659, 0.6471137159075712, 0.3307470103527586, 0.014380304797946027, 0.29264907588078015, 0.3901987678410402, 0.09754969196026005, 0.2438742299006501, 0.9661546174815099, 0.16260712707564284, 0.5420237569188094, 0.2710118784594047, 0.8984988151065499, 0.08984988151065498, 0.022462470377663746, 0.5498093910706926, 0.4276295263883165, 0.9129207324524372, 0.07607672770436977, 0.9631491019300706, 0.9794970398791755, 0.9180418359287659, 0.9180418359287659, 0.882559979579333, 0.9180418359287659, 0.9082816825696604, 0.20930613449724156, 0.6279184034917247, 0.8075216828836416, 0.2018804207209104, 0.8820473543752603, 0.8374872665439392, 0.8820473543752603, 0.5788059960280227, 0.2794235842893903, 0.05987648234772649, 0.09979413724621082, 0.7907721311592532, 0.9121698396961131, 0.09495730512999358, 0.9495730512999357, 0.9642260472356393, 0.8246258854285633, 0.1680348857903789, 0.8401744289518944, 0.9700922701431416, 0.8820169330455548, 0.765667250830881, 0.1968858644993694, 0.0218762071665966, 0.8822405492167124, 0.8920371612367304, 0.4829244995327807, 0.4829244995327807, 0.8820473543752603, 0.9180418359287659, 0.882559979579333, 0.8820473543752603, 0.8822405492167124, 0.7270245666052072, 0.25965163093043114, 0.8094009574648549, 0.1839547630601943, 0.9180418359287659, 0.4507233314317447, 0.6009644419089929, 0.9776917309125773, 0.991197376062217, 0.932980213509914, 0.9508703815508761, 0.026413066154191006, 0.013206533077095503, 0.8786427112598547, 0.8442879301640785, 0.10006375468611302, 0.05628586201093857, 0.7887236479103347, 0.04974089600845406, 0.09948179201690811, 0.845595232143719, 0.882559979579333, 0.3782092139920695, 0.04202324599911884, 0.4622557059903072, 0.08404649199823767, 0.9904510512471566, 0.8551509816513281, 0.13156168948481972, 0.7706105353719027, 0.9180418359287659, 0.9095939277864048, 0.5322512909353766, 0.0980462904354641, 0.32215209714509635, 0.042019838758056045, 0.9796306228638448, 0.882559979579333, 0.8494676165614882, 0.13324982220572362, 0.016656227775715453, 0.5398142288951271, 0.41985551136287663, 0.9636939356465933, 0.7888479766503805, 0.42871371439384826, 0.5716182858584644, 0.9922044515438676, 0.3536491121498909, 0.17682455607494546, 0.29470759345824243, 0.17682455607494546, 0.28278693629309415, 0.28278693629309415, 0.35348367036636763, 1.0040152848372288, 0.8730158181425095, 0.10393045454077494, 0.02078609090815499, 0.6813294048798498, 0.31795372227726326, 0.4650296256391921, 0.4650296256391921, 0.8840183697102013, 0.0813513837156627, 0.01627027674313254, 0.01898198953365463, 0.8822405492167124, 0.47404404630099745, 0.18232463319269132, 0.1093947799156148, 0.2187895598312296, 0.8264499352285619, 0.14662821431474485, 0.013329837664976805, 0.013329837664976805, 1.0041634344670465, 0.5305033655359055, 0.17683445517863514, 0.17683445517863514, 0.11788963678575677, 0.5233252575033802, 0.45790960031545763], \"Term\": [\"absolutely\", \"acceptablei\", \"again\", \"ago\", \"ago\", \"ago\", \"almost\", \"almost\", \"already\", \"also\", \"also\", \"always\", \"always\", \"always\", \"apologize\", \"apple\", \"apple\", \"apple\", \"arrive\", \"assortment\", \"awesome\", \"awesome\", \"awesome\", \"bag\", \"be\", \"be\", \"be\", \"be\", \"beer\", \"beer\", \"better\", \"black\", \"black\", \"black\", \"blend\", \"blend\", \"bottle\", \"bottle\", \"bottle\", \"bottle\", \"buy\", \"buy\", \"buy\", \"cabernet\", \"can\", \"can\", \"cancel\", \"cancel\", \"case\", \"case\", \"case\", \"cause\", \"cause\", \"cent\", \"chardonnay\", \"chardonnay\", \"chardonnay\", \"charge\", \"chinese\", \"cloudy\", \"cocktail\", \"coin\", \"collect\", \"collection\", \"collection\", \"complaint\", \"consider\", \"consider\", \"control\", \"cooler\", \"cork\", \"cork\", \"country\", \"dark\", \"day\", \"day\", \"day\", \"day\", \"decide\", \"decide\", \"decide\", \"decision\", \"definitely\", \"delicious\", \"deliver\", \"deliver\", \"delivery\", \"describe\", \"disappoint\", \"disappoint\", \"disappoint\", \"disappointing\", \"drain\", \"drain\", \"drank\", \"dressing\", \"drink\", \"drink\", \"drink\", \"dry\", \"dry\", \"dump\", \"dump\", \"embarrassed\", \"enjoy\", \"enjoy\", \"enjoy\", \"especially\", \"especially\", \"even\", \"even\", \"everyone\", \"excellent\", \"excite\", \"expression\", \"fabulous\", \"family\", \"family\", \"family\", \"far\", \"far\", \"favorite\", \"favorite\", \"favorite\", \"find\", \"find\", \"find\", \"first\", \"first\", \"first\", \"flag\", \"flavor\", \"flavor\", \"flavor\", \"flavorful\", \"foot\", \"friend\", \"friend\", \"friend\", \"friend\", \"game\", \"garbage\", \"generally\", \"german\", \"get\", \"get\", \"get\", \"get\", \"gift\", \"gift\", \"gifted\", \"giftthis\", \"ginseng\", \"give\", \"give\", \"give\", \"give\", \"glass\", \"glass\", \"go\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"great\", \"great\", \"great\", \"great\", \"green_tea\", \"hand\", \"hand\", \"hassle\", \"have\", \"have\", \"have\", \"highly\", \"hook\", \"hope\", \"horrible\", \"horrible\", \"horrify\", \"immediately\", \"impact\", \"juicer\", \"least\", \"least\", \"least\", \"local\", \"long\", \"love\", \"love\", \"luckily\", \"make\", \"make\", \"make\", \"make\", \"mispronounce\", \"miss\", \"money\", \"much\", \"much\", \"must\", \"must\", \"neat\", \"neat\", \"neat\", \"never\", \"never\", \"new\", \"new\", \"next\", \"next\", \"next\", \"nice\", \"nice\", \"nice\", \"oaky\", \"oaky\", \"offensive\", \"opinion\", \"option\", \"order\", \"order\", \"order\", \"pair\", \"pair\", \"palate\", \"past\", \"perfect\", \"period\", \"personally\", \"pinot\", \"plastic\", \"pleasure\", \"poor\", \"pour\", \"pour\", \"price\", \"price\", \"price\", \"price\", \"private\", \"promotion\", \"purchase\", \"purchase\", \"purchase\", \"quality\", \"quality\", \"quality\", \"quality\", \"quite\", \"qvc\", \"qvc\", \"qvc\", \"really\", \"really\", \"really\", \"receive\", \"receive\", \"red\", \"red\", \"refreshing\", \"refund\", \"regret\", \"repeatedly\", \"reputable\", \"reserve\", \"rest\", \"restaurant\", \"restaurant\", \"rise\", \"rise\", \"rotten\", \"salad\", \"same\", \"say\", \"say\", \"say\", \"say\", \"scotch\", \"second\", \"send\", \"send\", \"set\", \"several\", \"shipment\", \"shipment\", \"sip\", \"smile\", \"smooth\", \"smooth\", \"smooth\", \"social\", \"soda\", \"son\", \"son\", \"sorry\", \"sound\", \"spend\", \"spoil\", \"spread\", \"still\", \"still\", \"store\", \"store\", \"sub\", \"support\", \"support\", \"suppose\", \"sure\", \"surprise\", \"sweet\", \"sweet\", \"sweet\", \"tannic\", \"taste\", \"taste\", \"taste\", \"tasti\", \"tea\", \"tea\", \"tea\", \"text\", \"thank\", \"thank\", \"thank\", \"thank\", \"think\", \"time\", \"time\", \"tonight\", \"tout\", \"truly\", \"try\", \"try\", \"try\", \"try\", \"unfortunately\", \"upset\", \"use\", \"use\", \"use\", \"usually\", \"usually\", \"value\", \"varietal\", \"visit\", \"visit\", \"wait\", \"way\", \"way\", \"way\", \"way\", \"week\", \"week\", \"week\", \"weekend\", \"well\", \"well\", \"well\", \"white\", \"white\", \"whole\", \"whole\", \"wine\", \"wine\", \"wine\", \"wine\", \"word\", \"work\", \"work\", \"work\", \"work\", \"would\", \"would\", \"would\", \"would\", \"write\", \"year\", \"year\", \"year\", \"year\", \"\\u00bdi_\\u00bdi\", \"\\u00bdi_\\u00bdi\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 2, 1, 3]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el721406999605740323743764633\", ldavis_el721406999605740323743764633_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el721406999605740323743764633\", ldavis_el721406999605740323743764633_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el721406999605740323743764633\", ldavis_el721406999605740323743764633_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "3      0.133824 -0.018729       1        1  63.233510\n",
              "1      0.073546  0.091417       2        1  13.872044\n",
              "0     -0.048975 -0.143764       3        1  12.153376\n",
              "2     -0.158394  0.071075       4        1  10.741070, topic_info=         Term        Freq       Total Category  logprob  loglift\n",
              "41       love  123.000000  123.000000  Default  30.0000  30.0000\n",
              "229  purchase   69.000000   69.000000  Default  29.0000  29.0000\n",
              "191       try   71.000000   71.000000  Default  28.0000  28.0000\n",
              "586       tea   20.000000   20.000000  Default  27.0000  27.0000\n",
              "123       buy   89.000000   89.000000  Default  26.0000  26.0000\n",
              "..        ...         ...         ...      ...      ...      ...\n",
              "3        wine    6.946167  368.770617   Topic4  -4.9635  -1.7409\n",
              "21       good    5.909605  148.866253   Topic4  -5.1251  -0.9954\n",
              "540       say    5.078261   50.103144   Topic4  -5.2767  -0.0580\n",
              "17     bottle    5.275076  109.950715   Topic4  -5.2387  -0.8059\n",
              "241      rise    4.679019   24.767137   Topic4  -5.3586   0.5647\n",
              "\n",
              "[284 rows x 6 columns], token_table=      Topic      Freq         Term\n",
              "term                              \n",
              "303       1  0.991115   absolutely\n",
              "1568      4  0.882560  acceptablei\n",
              "533       1  0.970006        again\n",
              "169       1  0.500439          ago\n",
              "169       3  0.417032          ago\n",
              "...     ...       ...          ...\n",
              "379       2  0.176834         year\n",
              "379       3  0.176834         year\n",
              "379       4  0.117890         year\n",
              "1638      2  0.523325        ½i_½i\n",
              "1638      4  0.457910        ½i_½i\n",
              "\n",
              "[386 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 2, 1, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYklN-JRT0O7"
      },
      "source": [
        "## Building LDA Mallet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H9rMVYXT0O8"
      },
      "source": [
        "from gensim.test.utils import common_corpus, common_dictionary\n",
        "from gensim.models.wrappers import LdaMallet\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "Wt6Pzkr2T0O8",
        "outputId": "f97028fb-5b0c-4150-b9b6-cf9411c5111e"
      },
      "source": [
        "import os\n",
        "os.environ.update({\"MALLET_HOME\":r\"C:\\mallet-2.0.8\"})\n",
        "\n",
        "print(os.environ['MALLET_HOME'])\n",
        "mallet_path = os.environ['MALLET_HOME'] + r'\\bin\\mallet' # update this path\n",
        "print(mallet_path)\n",
        "\n",
        "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=4, id2word=id2word)\n",
        "\n",
        "result = (ldamallet.show_topics(num_topics=3, num_words=10,formatted=False))\n",
        "for each in result:\n",
        "    print (each)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\mallet-2.0.8\n",
            "C:\\mallet-2.0.8\\bin\\mallet\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-9fa248901edd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mldamallet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mldamallet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformatted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinferencer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmallet_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' train-topics --input %s --num-topics %s  --alpha %s --optimize-interval %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;34m'--num-threads %s --output-state %s --output-doc-topics %s --output-topic-keys %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36mconvert_input\u001b[0;34m(self, corpus, infer, serialize_corpus)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcorpustxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcorpusmallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"converting temporary corpus to MALLET format with %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m   1877\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1879\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1880\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1881\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'C:\\mallet-2.0.8\\bin\\mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/70d80d_corpus.txt --output /tmp/70d80d_corpus.mallet' returned non-zero exit status 127."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDbw38SBT0O8",
        "outputId": "273c2e19-7f22-45a0-837e-365450030cae"
      },
      "source": [
        "# Show Topics\n",
        "pprint(ldamallet.show_topics(formatted=False))\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_ldamallet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  [('tv', 0.017189041985734094),\n",
            "   ('screen', 0.014578206393424192),\n",
            "   ('device', 0.014365841775867885),\n",
            "   ('make', 0.013072916016039774),\n",
            "   ('app', 0.010686937077613022),\n",
            "   ('feature', 0.010012367115963573),\n",
            "   ('update', 0.009344043172477546),\n",
            "   ('time', 0.008794393574096513),\n",
            "   ('video', 0.008788147555933093),\n",
            "   ('review', 0.008338434248166793)]),\n",
            " (1,\n",
            "  [('product', 0.10187923233876453),\n",
            "   ('buy', 0.05137209096016796),\n",
            "   ('work', 0.04295176981991306),\n",
            "   ('mobile', 0.03303811692344087),\n",
            "   ('bad', 0.02608894934500399),\n",
            "   ('money', 0.02608155661353757),\n",
            "   ('time', 0.02445515569092468),\n",
            "   ('month', 0.02040393884732531),\n",
            "   ('issue', 0.019354170979093355),\n",
            "   ('book', 0.01882928704497738)]),\n",
            " (2,\n",
            "  [('phone', 0.13641630606272873),\n",
            "   ('camera', 0.07392326173626705),\n",
            "   ('battery', 0.07309185416980354),\n",
            "   ('charge', 0.035783257939287605),\n",
            "   ('display', 0.027737589441778558),\n",
            "   ('day', 0.027403717111938883),\n",
            "   ('fast', 0.02295208604740987),\n",
            "   ('performance', 0.022002841188061773),\n",
            "   ('back', 0.012955555701033695),\n",
            "   ('hour', 0.010703554103683725)]),\n",
            " (3,\n",
            "  [('good', 0.26878522348562844),\n",
            "   ('quality', 0.09182700740503481),\n",
            "   ('price', 0.056632120005795906),\n",
            "   ('nice', 0.042577043629458466),\n",
            "   ('sound', 0.03732259565154392),\n",
            "   ('great', 0.03066492789433145),\n",
            "   ('life', 0.026943345001410848),\n",
            "   ('awesome', 0.024472457998734053),\n",
            "   ('excellent', 0.02358019324776743),\n",
            "   ('picture', 0.0203161820220092)])]\n",
            "\n",
            "Coherence Score:  0.6255511995131074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyN1e1zOT0O9"
      },
      "source": [
        "## How to find the optimal number of topics for LDA?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epEgD3LmT0O9",
        "outputId": "8854efe8-72e0-4f3b-bbbc-cf0f230df823"
      },
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values\n",
        "# Can take a long time to run.\n",
        "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=6)\n",
        "# Show graph\n",
        "limit=40; start=2; step=6;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or7y8sbDT0O-",
        "outputId": "fe77141b-65bd-47cb-9b1c-89cc82506231"
      },
      "source": [
        "# Print the coherence scores\n",
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num Topics = 2  has Coherence Value of 0.5624\n",
            "Num Topics = 8  has Coherence Value of 0.6417\n",
            "Num Topics = 14  has Coherence Value of 0.6267\n",
            "Num Topics = 20  has Coherence Value of 0.6092\n",
            "Num Topics = 26  has Coherence Value of 0.6015\n",
            "Num Topics = 32  has Coherence Value of 0.5998\n",
            "Num Topics = 38  has Coherence Value of 0.5758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EShNrT3wT0O-",
        "outputId": "98730e35-cf61-459e-b8bf-93d2cf63fe9f"
      },
      "source": [
        "# Select the model and print the topics\n",
        "optimal_model = model_list[1]\n",
        "model_topics = optimal_model.show_topics(formatted=False)\n",
        "pprint(optimal_model.print_topics(num_words=10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.171*\"battery\" + 0.077*\"charge\" + 0.069*\"life\" + 0.066*\"day\" + '\n",
            "  '0.054*\"good\" + 0.053*\"camera\" + 0.050*\"fast\" + 0.029*\"performance\" + '\n",
            "  '0.023*\"hour\" + 0.019*\"average\"'),\n",
            " (1,\n",
            "  '0.035*\"book\" + 0.023*\"give\" + 0.020*\"make\" + 0.016*\"apple\" + 0.015*\"thing\" '\n",
            "  '+ 0.015*\"review\" + 0.014*\"read\" + 0.014*\"find\" + 0.014*\"year\" + '\n",
            "  '0.013*\"time\"'),\n",
            " (2,\n",
            "  '0.035*\"tv\" + 0.029*\"device\" + 0.021*\"app\" + 0.019*\"update\" + '\n",
            "  '0.016*\"feature\" + 0.016*\"option\" + 0.015*\"support\" + 0.014*\"smart\" + '\n",
            "  '0.013*\"video\" + 0.012*\"play\"'),\n",
            " (3,\n",
            "  '0.088*\"work\" + 0.066*\"mobile\" + 0.052*\"bad\" + 0.048*\"time\" + 0.044*\"issue\" '\n",
            "  '+ 0.038*\"problem\" + 0.037*\"buy\" + 0.031*\"month\" + 0.027*\"call\" + '\n",
            "  '0.023*\"poor\"'),\n",
            " (4,\n",
            "  '0.203*\"product\" + 0.066*\"buy\" + 0.052*\"money\" + 0.029*\"worth\" + '\n",
            "  '0.022*\"delivery\" + 0.021*\"purchase\" + 0.018*\"happy\" + 0.017*\"service\" + '\n",
            "  '0.017*\"receive\" + 0.014*\"return\"'),\n",
            " (5,\n",
            "  '0.295*\"phone\" + 0.102*\"price\" + 0.076*\"great\" + 0.040*\"good\" + '\n",
            "  '0.037*\"amazing\" + 0.036*\"range\" + 0.033*\"feature\" + 0.033*\"love\" + '\n",
            "  '0.029*\"awesome\" + 0.024*\"budget\"'),\n",
            " (6,\n",
            "  '0.432*\"good\" + 0.181*\"quality\" + 0.084*\"nice\" + 0.074*\"sound\" + '\n",
            "  '0.037*\"picture\" + 0.027*\"excellent\" + 0.011*\"build\" + 0.010*\"earphone\" + '\n",
            "  '0.010*\"bass\" + 0.009*\"clarity\"'),\n",
            " (7,\n",
            "  '0.088*\"camera\" + 0.051*\"display\" + 0.035*\"screen\" + 0.024*\"back\" + '\n",
            "  '0.019*\"pro\" + 0.017*\"front\" + 0.016*\"light\" + 0.015*\"low\" + 0.015*\"con\" + '\n",
            "  '0.014*\"feel\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvDeZEpIT0O-"
      },
      "source": [
        "## Finding the dominant topic in each sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EZ1yOu-T0O-",
        "outputId": "453209ad-f527-409e-a155-f6575cf06fd9"
      },
      "source": [
        "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
        "    # Init output\n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "    return(sent_topics_df)\n",
        "\n",
        "\n",
        "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
        "\n",
        "# Format\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "\n",
        "# Show\n",
        "df_dominant_topic.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document_No</th>\n",
              "      <th>Dominant_Topic</th>\n",
              "      <th>Topic_Perc_Contrib</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1250</td>\n",
              "      <td>battery, charge, life, day, good, camera, fast...</td>\n",
              "      <td>I liked it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.2385</td>\n",
              "      <td>camera, display, screen, back, pro, front, lig...</td>\n",
              "      <td>I bought the phone on Amazon and been using my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.1561</td>\n",
              "      <td>phone, price, great, good, amazing, range, fea...</td>\n",
              "      <td>Awesome book at reasonable price, must buy ......</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.1356</td>\n",
              "      <td>good, quality, nice, sound, picture, excellent...</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.1830</td>\n",
              "      <td>book, give, make, apple, thing, review, read, ...</td>\n",
              "      <td>The book is fine,not bad,contains nice concept...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.1568</td>\n",
              "      <td>tv, device, app, update, feature, option, supp...</td>\n",
              "      <td>Nice tv and pic quality .good custmer srrvice ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.2295</td>\n",
              "      <td>tv, device, app, update, feature, option, supp...</td>\n",
              "      <td>The iPhone 7 is legitimately among the most in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1394</td>\n",
              "      <td>battery, charge, life, day, good, camera, fast...</td>\n",
              "      <td>20000 mAH, what more you need. Super product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1445</td>\n",
              "      <td>battery, charge, life, day, good, camera, fast...</td>\n",
              "      <td>The company should give more Bettany backup an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.1394</td>\n",
              "      <td>phone, price, great, good, amazing, range, fea...</td>\n",
              "      <td>Very good phone</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
              "0            0             0.0              0.1250   \n",
              "1            1             7.0              0.2385   \n",
              "2            2             5.0              0.1561   \n",
              "3            3             6.0              0.1356   \n",
              "4            4             1.0              0.1830   \n",
              "5            5             2.0              0.1568   \n",
              "6            6             2.0              0.2295   \n",
              "7            7             0.0              0.1394   \n",
              "8            8             0.0              0.1445   \n",
              "9            9             5.0              0.1394   \n",
              "\n",
              "                                            Keywords  \\\n",
              "0  battery, charge, life, day, good, camera, fast...   \n",
              "1  camera, display, screen, back, pro, front, lig...   \n",
              "2  phone, price, great, good, amazing, range, fea...   \n",
              "3  good, quality, nice, sound, picture, excellent...   \n",
              "4  book, give, make, apple, thing, review, read, ...   \n",
              "5  tv, device, app, update, feature, option, supp...   \n",
              "6  tv, device, app, update, feature, option, supp...   \n",
              "7  battery, charge, life, day, good, camera, fast...   \n",
              "8  battery, charge, life, day, good, camera, fast...   \n",
              "9  phone, price, great, good, amazing, range, fea...   \n",
              "\n",
              "                                                Text  \n",
              "0                                         I liked it  \n",
              "1  I bought the phone on Amazon and been using my...  \n",
              "2  Awesome book at reasonable price, must buy ......  \n",
              "3                                               good  \n",
              "4  The book is fine,not bad,contains nice concept...  \n",
              "5  Nice tv and pic quality .good custmer srrvice ...  \n",
              "6  The iPhone 7 is legitimately among the most in...  \n",
              "7       20000 mAH, what more you need. Super product  \n",
              "8  The company should give more Bettany backup an...  \n",
              "9                                    Very good phone  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQJa0E3bT0O_"
      },
      "source": [
        "## Find the most representative document for each topic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVvjxefrT0O_",
        "outputId": "5038dcfc-6ba6-42e5-89e0-fc8c79a8d2ad"
      },
      "source": [
        "# Group top 5 sentences under each topic\n",
        "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
        "\n",
        "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
        "\n",
        "for i, grp in sent_topics_outdf_grpd:\n",
        "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
        "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
        "                                            axis=0)\n",
        "\n",
        "# Reset Index    \n",
        "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Format\n",
        "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
        "\n",
        "# Show\n",
        "sent_topics_sorteddf_mallet.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_Num</th>\n",
              "      <th>Topic_Perc_Contrib</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3512</td>\n",
              "      <td>battery, charge, life, day, good, camera, fast...</td>\n",
              "      <td>When I am trying to charge with realme 5w char...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7297</td>\n",
              "      <td>book, give, make, apple, thing, review, read, ...</td>\n",
              "      <td>Not everyone dares to follow their dream, even...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.7275</td>\n",
              "      <td>tv, device, app, update, feature, option, supp...</td>\n",
              "      <td>I had this device in wish list since launch. W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.3729</td>\n",
              "      <td>work, mobile, bad, time, issue, problem, buy, ...</td>\n",
              "      <td>hey Guy's, I ordered SAMSUNG M30s on 29 Sep an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.3950</td>\n",
              "      <td>product, buy, money, worth, delivery, purchase...</td>\n",
              "      <td>Please dont buy Samsung products.Samsung Cheat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Topic_Num  Topic_Perc_Contrib  \\\n",
              "0        0.0              0.3512   \n",
              "1        1.0              0.7297   \n",
              "2        2.0              0.7275   \n",
              "3        3.0              0.3729   \n",
              "4        4.0              0.3950   \n",
              "\n",
              "                                            Keywords  \\\n",
              "0  battery, charge, life, day, good, camera, fast...   \n",
              "1  book, give, make, apple, thing, review, read, ...   \n",
              "2  tv, device, app, update, feature, option, supp...   \n",
              "3  work, mobile, bad, time, issue, problem, buy, ...   \n",
              "4  product, buy, money, worth, delivery, purchase...   \n",
              "\n",
              "                                                Text  \n",
              "0  When I am trying to charge with realme 5w char...  \n",
              "1  Not everyone dares to follow their dream, even...  \n",
              "2  I had this device in wish list since launch. W...  \n",
              "3  hey Guy's, I ordered SAMSUNG M30s on 29 Sep an...  \n",
              "4  Please dont buy Samsung products.Samsung Cheat...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjo-V38yT0O_"
      },
      "source": [
        "## Topic distribution across documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpJ-sQZyT0PA",
        "outputId": "dbba0fb4-0cde-4273-cd6b-00187d50422f"
      },
      "source": [
        "# Number of Documents for Each Topic\n",
        "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
        "\n",
        "# Percentage of Documents for Each Topic\n",
        "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
        "\n",
        "# Topic Number and Keywords\n",
        "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
        "\n",
        "# Concatenate Column wise\n",
        "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
        "\n",
        "# Change Column names\n",
        "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
        "\n",
        "# Show\n",
        "df_dominant_topics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dominant_Topic</th>\n",
              "      <th>Topic_Keywords</th>\n",
              "      <th>Num_Documents</th>\n",
              "      <th>Perc_Documents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>battery, charge, life, day, good, camera, fast...</td>\n",
              "      <td>10725.0</td>\n",
              "      <td>0.1761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>camera, display, screen, back, pro, front, lig...</td>\n",
              "      <td>5793.0</td>\n",
              "      <td>0.0951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>phone, price, great, good, amazing, range, fea...</td>\n",
              "      <td>4412.0</td>\n",
              "      <td>0.0725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>good, quality, nice, sound, picture, excellent...</td>\n",
              "      <td>6193.0</td>\n",
              "      <td>0.1017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>book, give, make, apple, thing, review, read, ...</td>\n",
              "      <td>9902.0</td>\n",
              "      <td>0.1626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60884.0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>battery, charge, life, day, good, camera, fast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60885.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>good, quality, nice, sound, picture, excellent...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60886.0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>product, buy, money, worth, delivery, purchase...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60887.0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>battery, charge, life, day, good, camera, fast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60888.0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>battery, charge, life, day, good, camera, fast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60889 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Dominant_Topic                                     Topic_Keywords  \\\n",
              "0.0                 0.0  battery, charge, life, day, good, camera, fast...   \n",
              "1.0                 7.0  camera, display, screen, back, pro, front, lig...   \n",
              "2.0                 5.0  phone, price, great, good, amazing, range, fea...   \n",
              "3.0                 6.0  good, quality, nice, sound, picture, excellent...   \n",
              "4.0                 1.0  book, give, make, apple, thing, review, read, ...   \n",
              "...                 ...                                                ...   \n",
              "60884.0             0.0  battery, charge, life, day, good, camera, fast...   \n",
              "60885.0             6.0  good, quality, nice, sound, picture, excellent...   \n",
              "60886.0             4.0  product, buy, money, worth, delivery, purchase...   \n",
              "60887.0             0.0  battery, charge, life, day, good, camera, fast...   \n",
              "60888.0             0.0  battery, charge, life, day, good, camera, fast...   \n",
              "\n",
              "         Num_Documents  Perc_Documents  \n",
              "0.0            10725.0          0.1761  \n",
              "1.0             5793.0          0.0951  \n",
              "2.0             4412.0          0.0725  \n",
              "3.0             6193.0          0.1017  \n",
              "4.0             9902.0          0.1626  \n",
              "...                ...             ...  \n",
              "60884.0            NaN             NaN  \n",
              "60885.0            NaN             NaN  \n",
              "60886.0            NaN             NaN  \n",
              "60887.0            NaN             NaN  \n",
              "60888.0            NaN             NaN  \n",
              "\n",
              "[60889 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4PxVrdZT0PA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}