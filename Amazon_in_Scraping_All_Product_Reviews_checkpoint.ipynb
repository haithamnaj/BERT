{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Amazon.in Scraping All Product Reviews-checkpoint.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvnzXkbIxdPO"
      },
      "source": [
        "# Amazon Product Review Scraping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_95x-ruxdPP"
      },
      "source": [
        "This project aims to scrape reviews of any product link provided using Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLQVZvo3xdPQ",
        "outputId": "877a432a-04c3-48e2-91e4-3557a5bb1c15"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "product_link = input('Enter the product link: ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the product link: https://www.amazon.in/Test-Exclusive-608/dp/B07HGBMJT6/ref=sr_1_1?keywords=oneplus+7&qid=1563085781&s=gateway&smid=A35FCS7U51TK3C&sr=8-1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl4Oe_zJxdPR",
        "outputId": "019620e4-e1c5-4957-ef84-b3e4cc47e981"
      },
      "source": [
        "\n",
        "product_page = requests.get(product_link)\n",
        "print(product_page)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Response [503]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NC2pdhaExdPS",
        "outputId": "6c493e82-5fb8-4a01-9aef-668daf528f18"
      },
      "source": [
        "product_page_soup = BeautifulSoup(product_page.text, 'html.parser')\n",
        "print(product_page_soup)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<html>\n",
            "<head>\n",
            "<title>503 - Service Unavailable Error</title>\n",
            "</head>\n",
            "<body bgcolor=\"#FFFFFF\" text=\"#000000\">\n",
            "<!--\n",
            "        To discuss automated access to Amazon data please contact api-services-support@amazon.com.\n",
            "        For information about migrating to our APIs refer to our Marketplace APIs at https://developer.amazonservices.in/ref=rm_5_sv, or our Product Advertising API at https://affiliate-program.amazon.in/gp/advertising/api/detail/main.html/ref=rm_5_ac for advertising use cases.\n",
            "-->\n",
            "<center>\n",
            "<a href=\"https://www.amazon.in/ref=cs_503_logo/\">\n",
            "<img alt=\"Amazon.in\" border=\"0\" height=\"45\" src=\"https://images-eu.ssl-images-amazon.com/images/G/31/x-locale/communities/people/logo.gif\" width=\"200\"/></a>\n",
            "<p align=\"center\">\n",
            "<font face=\"Verdana,Arial,Helvetica\">\n",
            "<font color=\"#CC6600\" size=\"+2\"><b>Oops!</b></font><br/>\n",
            "<b>It's rush hour and traffic is piling up on that page. Please try again in a short while.<br/>If you were trying to place an order, it will not have been processed at this time.</b><p>\n",
            "<img alt=\"*\" border=\"0\" height=\"9\" src=\"https://images-eu.ssl-images-amazon.com/images/G/02/x-locale/common/orange-arrow.gif\" width=\"10\"/>\n",
            "<b><a href=\"https://www.amazon.in/ref=cs_503_link/\">Go to the Amazon.in home page to continue shopping</a></b>\n",
            "</p></font>\n",
            "</p></center>\n",
            "</body>\n",
            "</html>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "Ld66u1fTxdPT",
        "outputId": "8f74f3e0-309c-4157-d618-a5078fe3d9d8"
      },
      "source": [
        "see_all_reviews = product_page_soup.find(id=\"dp-summary-see-all-reviews\")\n",
        "print(see_all_reviews)\n",
        "all_reviews_url =  'https://www.amazon.in' + see_all_reviews['href']\n",
        "print(all_reviews_url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a9ca43586c4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msee_all_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduct_page_soup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dp-summary-see-all-reviews\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msee_all_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mall_reviews_url\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m'https://www.amazon.in'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msee_all_reviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_reviews_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEBAxnyLxdPT"
      },
      "source": [
        "all_reviews_page = requests.get(all_reviews_url)\n",
        "all_reviews_page_soup = BeautifulSoup(all_reviews_page.text, 'html.parser')\n",
        "\n",
        "#do\n",
        "i=1\n",
        "# review_id = [i['id'] for i in all_reviews_page_soup.find_all(class_='a-section review aok-relative')[2:]]\n",
        "names = list([i.text for i in all_reviews_page_soup.find_all(class_='a-profile-name')[2:]])\n",
        "ratings = list([i.find(class_='a-icon-alt').text[:3] for i in all_reviews_page_soup.find_all(class_='a-section celwidget')])\n",
        "title = list([i.span.text for i in all_reviews_page_soup.find_all(class_='review-title')[2:]])\n",
        "date = list([i.text for i in all_reviews_page_soup.find_all(class_='review-date')[2:]])\n",
        "text = list([i.span.text for i in all_reviews_page_soup.find_all(class_='review-text-content')])\n",
        "#while\n",
        "# print(type(all_reviews_page_soup.find(class_='a-pagination').find_all('li')[1].a))\n",
        "try:\n",
        "    while all_reviews_page_soup.find(class_='a-pagination'):\n",
        "        if all_reviews_page_soup.find(class_='a-pagination').find_all('li')[1].a:\n",
        "            print(i)\n",
        "            i+=1\n",
        "            next_url = 'https://www.amazon.in' + all_reviews_page_soup.find(class_='a-pagination').find_all('li')[1].a['href']\n",
        "            all_reviews_page = requests.get(next_url)\n",
        "            all_reviews_page_soup = BeautifulSoup(all_reviews_page.text, 'html.parser')\n",
        "    #         review_id.append([i['id'] for i in all_reviews_page_soup.find_all(class_='a-section review aok-relative')[2:]])\n",
        "            temp_names = [i.text for i in all_reviews_page_soup.find_all(class_='a-profile-name')[2:]]\n",
        "            if temp_names:\n",
        "                names.append(temp_names)\n",
        "            else:\n",
        "                names.append('')\n",
        "            temp_ratings = [i.find(class_='a-icon-alt').text[:3] for i in all_reviews_page_soup.find_all(class_='a-section celwidget')]\n",
        "            if temp_ratings:\n",
        "                ratings.append(temp_ratings)\n",
        "            else:\n",
        "                ratings.append('')\n",
        "            temp_title = [i.span.text for i in all_reviews_page_soup.find_all(class_='review-title')[2:]]\n",
        "            if temp_title:\n",
        "                title.append(temp_title)\n",
        "            else:\n",
        "                title.append('')\n",
        "            temp_date = [i.text for i in all_reviews_page_soup.find_all(class_='review-date')[2:]]\n",
        "            if temp_date:\n",
        "                date.append(temp_date)\n",
        "            else:\n",
        "                date.append('')\n",
        "            temp_text = [i.span.text for i in all_reviews_page_soup.find_all(class_='review-text-content')]\n",
        "            if temp_text:\n",
        "                text.append(temp_text)\n",
        "            else:\n",
        "                text.append('')\n",
        "        else:\n",
        "            break\n",
        "except Exception as e:\n",
        "    print(e, type(all_reviews_page_soup.find(class_='a-pagination')))\n",
        "print('Name'+str(len(names))+'Ratings'+str(len(ratings))+'Title'+str(len(title))+'Date'+str(len(date))+'Text'+str(len(text)))\n",
        "reviews_dict = {'Name':names, 'Ratings':ratings, 'Title':title, 'Date':date, 'Text':text}\n",
        "#print(reviews_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmZlONK6xdPU"
      },
      "source": [
        "reviews_df = pd.DataFrame.from_dict(reviews_dict)\n",
        "print(reviews_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS2fhVs5xdPU"
      },
      "source": [
        "Saving the the Reviews dataframe to a CSV file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvGHoxw-xdPU"
      },
      "source": [
        "reviews_df.to_csv(r'.\\Review.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjC69XAfxdPV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}